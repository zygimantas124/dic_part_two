--algo
dqn
--max_episodes
2000
--log_interval
10
--save_model_path
logs/model.pth
--seed
0
--max_episode_steps
5000
--device
cpu
--target_update_freq
5000
--buffer_size
20000
--min_replay_size
20000
--gamma
0.99
--reward_step
-1
--reward_collision
-5
--epsilon_start
1
--epsilon_decay
0.995
--min_replay_size
1000
--warmstart
10
# env config
--env_name
open_office_simple
--show_walls
--show_obstacles
--hide_carpets

